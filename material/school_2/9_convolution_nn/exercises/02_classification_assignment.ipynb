{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with CNN\n",
    "\n",
    "[Saeed Salehi, Philipp Seegerer, PyTorch Tutorials]\n",
    "\n",
    "Our goal here is to build our first convolution neural net for classification task and get familiar with the classes and functions that are commonly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header\n",
    "import sys\n",
    "sys.path.append(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please define the data directory\n",
    "data_root = \"./data\"\n",
    "assert os.path.exists(data_root), \"Data directory not found!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Before going further, we need to choose the hardware to train our model on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "num_workers, pin_memory = 4, False\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # NVIDIA GPU\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon (Metal)\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # CPU (slowest option)\n",
    "\n",
    "print(f\"Device set to {device}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to count the number of learble parameters in a model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Pytorch comes with a library dedicated to Vision tasks, called `torchvision`. Besides vision-related modules and classes. `torchvision` also comes with some popular datasets such as *MNIST*, *CelebA*, *CIFAR10* built-in. [TorchVision Built-in datasets](https://pytorch.org/vision/stable/datasets.html)\n",
    "\n",
    "Please note that if the data-files are not available, `torchvision` can download them for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please choose one of the two datasets and comment out the other\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "train_ds = MNIST(root=data_root,  # location for the data to be downloaded if not found\n",
    "                train=True,  # use the training set (if false, it will use the test set)\n",
    "                transform=torchvision.transforms.ToTensor(),  # transform the data to torch tensors\n",
    "                download=True,  # download the data if not found, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly splitting the dataset into 90% training and 10% validation\n",
    "n_train = int(0.9 * len(train_ds))\n",
    "n_val = len(train_ds) - n_train\n",
    "train_ds, val_ds = torch.utils.data.random_split(train_ds, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the first 5 images\n",
    "fig, axs = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(train_ds[i][0].squeeze(), cmap=\"gray\")\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Image Dataset\n",
    "\n",
    "Since not every dataset is already available in PyTorch, we need to learn how to build a class of our dataset that could *read* and *pre-process* the data samples for training. PyTorch comes with the base calss Dataset `torch.utils.data.Dataset` which could built further for any specific data and task.\n",
    "\n",
    "Even for the available datasets, we would often want to augment the images or change them to our desired shape or format. For pre-defined augmentations (transformations) we can pass them to `transform` argument in the dataset, but we could also build our own Dataset class.\n",
    "\n",
    "[illustration of transforms](https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py)\n",
    "\n",
    "[ Datasets & DataLoaders tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "every `Dataset` class can have any number of functions and attributes, but it must always include the three functions `__init__`, `__len__` which returns the length (number of samples) in the dataset and `__getitem__(i)` that takes i (an integer in the range of dataset length) and returns curated data-sample outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It's important to note that loading the whole dataset into the RAM is often impossible and unnecessary. Therefore it is important to design your `Dataset` to read the data from the hard-drive upon request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# ?Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will use create a custom dataset class to add noise and pre-built transformations.\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, ds_: Dataset, noise_level: float = 0.0):\n",
    "        self.ds = ds_  # the vanila dataset\n",
    "        self.noise_level = noise_level  # the noise level to be added to the images\n",
    "        \n",
    "        # >>>>> YOUR CODE HERE\n",
    "        raise NotImplementedError(\"Replace this line by your code.\")\n",
    "        self.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Pad((2, 2, 2, 2)),\n",
    "            ...  # include RandomRotation transform in the composition\n",
    "        ])\n",
    "        # <<<<< END YOUR CODE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        image, label = self.ds.__getitem__(i)\n",
    "\n",
    "        # apply the padding transformation\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        # add noise if the noise_level is greater than 0\n",
    "        if self.noise_level > 0.0:\n",
    "            image += self.noise_level * torch.randn_like(image)\n",
    "            image = torch.clamp(image, 0.0, 1.0)  # clip the values to be between 0 and 1\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the first 5 images with and without noise\n",
    "train_ds_n = CustomImageDataset(train_ds, noise_level=0.1)\n",
    "valid_ds_n = CustomImageDataset(val_ds, noise_level=0.0, )\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(train_ds[i][0].squeeze(), cmap=\"gray\")\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(train_ds_n[i][0].squeeze(), cmap=\"gray\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "The `Dataset` retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s `multiprocessing` to speed up data retrieval. DataLoader is an iterable that abstracts this complexity for us in an easy API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# ?DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds_n,  # the dataset to be used\n",
    "                              batch_size=64,  # the number of samples per batch\n",
    "                              shuffle=True,  # shuffle the dataset at every epoch\n",
    "                              )\n",
    "\n",
    "val_dataloader = DataLoader(valid_ds_n,  # the dataset to be used\n",
    "                            batch_size=64,  # the number of samples per batch\n",
    "                            shuffle=False,  # do not shuffle the dataset\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** above we only passed 3 arguments but you should familiarize yourself with other arguments such as `num_workers` and `pin_memory`, since they can effect the speed on which the data is prepared depending on your hardware.\n",
    "\n",
    "[Performance Tuning Guide](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Since `Dataloader` is of generator class, we can use it to iterate over the dataset\n",
    "for images, labels in train_dataloader:\n",
    "    print(f\"Images batch shape: {images.shape}, Labels batch shape: {labels.shape}\")\n",
    "    break\n",
    "\n",
    "# or using the `iter` function\n",
    "images, labels = next(iter(train_dataloader))\n",
    "print(f\"Batch size: {images.size(0)} \\n\"\n",
    "       \"Number of channels: {images.size(1)} \\n\"\n",
    "       \"Height: {images.size(2)} \\n\"\n",
    "       \"Width: {images.size(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network architecture\n",
    "\n",
    "Since Pooling does not have any learnable parameter, it can be done by `nn.MaxPool2d(kernel_size, stride)` or `F.max_pool2d(input, kernel_size, stride)`. This also applies to Dropout and activation functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # >>>>> YOUR CODE HERE\n",
    "        raise NotImplementedError(\"Replace this line by your code.\")\n",
    "        self.conv1 = ...  # nn.Conv2d with in_channels=1, out_channels=4, kernel_size=3, stride=1, padding='same'\n",
    "        self.conv2 = ...  # nn.Conv2d with in_channels=4, out_channels=8, kernel_size=3, stride=1, padding='same'\n",
    "        self.maxpool = ...  # nn.MaxPool2d with kernel_size=2, stride=2\n",
    "        # <<<<< END YOUR CODE\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding='same')\n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding='same')\n",
    "        # >>>>> YOUR CODE HERE\n",
    "        raise NotImplementedError(\"Replace this line by your code.\")\n",
    "        self.adapool = ...  # AdaptiveAvgPool2d withoutput_size=(4, 4)\n",
    "        # <<<<< END YOUR CODE\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.adapool(x)\n",
    "\n",
    "        x = x.view(-1, 256)  # Reshape to vector\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.25)\n",
    "        y = self.fc3(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = F.cross_entropy\n",
    "print(model)\n",
    "print(f\"The model has {count_parameters(model):,} learnable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, criterion, device):\n",
    "    \n",
    "    # Set network to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate over dataset\n",
    "    losses = list()\n",
    "    for data, target in data_loader:\n",
    "        # Move data to GPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Compute output\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute crossentropy loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Compute gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform gradient descent\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Set network to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Return loss at end of epoch\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(model, data_loader, criterion, device):\n",
    "    \n",
    "    label_loss = 0.0  # loss for the entire dataset\n",
    "    correct = 0  # number of correct predictions\n",
    "\n",
    "    # Set network to training mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over dataset\n",
    "        for data, target in data_loader:\n",
    "            # Move data to device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Compute output\n",
    "            output = model(data)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(output, target)\n",
    "            label_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Compute the number of correct predictions\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "        \n",
    "    label_loss /= len(data_loader.dataset)\n",
    "    correct_percent = 100.0 * correct / len(data_loader.dataset)\n",
    "\n",
    "    print(f\"Average Validation loss: {label_loss:.4f}, Validation Accuracy: {correct}/{len(data_loader.dataset)} ({correct_percent:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = list()\n",
    "for epoch in tqdm(range(5)):\n",
    "    epoch_losses = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    print(f\"Average loss in epoch {epoch}: {torch.tensor(epoch_losses).mean().item():.5f}\")\n",
    "    losses.extend(epoch_losses)\n",
    "\n",
    "eval_function(model, val_dataloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the learned kernels from the first Conv2d\n",
    "# >>>>> YOUR CODE HERE\n",
    "raise NotImplementedError(\"Replace this line by your code.\")\n",
    "conv1_kernels = ...  # get the kernels (weight attributes) of conv1 layer\n",
    "# <<<<< END YOUR CODE\n",
    "v_min, vmax = conv1_kernels.min(), conv1_kernels.max()\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.suptitle(\"Kernels from the first Conv2d layer\")\n",
    "for i in range(conv1_kernels.size(0)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(conv1_kernels[i][0], vmin=v_min, vmax=vmax)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
