{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer-Learning\n",
    "\n",
    "We fine-tune the last Fully-Connected layer in a pretrained ResNet18 on ImageNet1k to classify the Places365 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # header\n",
    "import sys\n",
    "sys.path.append(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please define the data directory\n",
    "data_root = \"./data\"\n",
    "assert os.path.exists(data_root), \"Data directory not found!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "num_workers, pin_memory = 4, False\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # NVIDIA GPU\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")  # Apple Silicon (Metal)\n",
    "else:\n",
    "    device = torch.device(\"cpu\") # CPU (slowest option)\n",
    "\n",
    "print(f\"Device set to {device}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to return the number of learble parameters in a model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Freezing all layers except the layer with the name \"fc\"\n",
    "def freez_not_fc(model: nn.Module):\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"fc\" not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device, pre_process):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct, total, loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x = pre_process(x)\n",
    "            y_hat = model(x)\n",
    "            loss += criterion(y_hat, y).item()\n",
    "            correct += (y_hat.argmax(1) == y).sum().item()\n",
    "            total += len(y)\n",
    "    return loss / len(val_loader), 100 * correct / total\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, device, pre_process, epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x = pre_process(x)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device, pre_process)\n",
    "        print(f\"Epoch {1 + epoch:3d} | Val loss {val_loss:.4f} | Val acc {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "`Places365` dataset\n",
    "\n",
    "Since the dataset is very large, for this exercise we use the validation dataset, split to two, and use it as train and validation set.\n",
    "\n",
    "[Torchvision built-in datasets](https://pytorch.org/vision/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = datasets.Places365(root=data_root, \n",
    "                              split='val', \n",
    "                              small=True,\n",
    "                            #   download=True, \n",
    "                              transform=transforms.ToTensor())\n",
    "class_names = val_ds.classes\n",
    "# randomly splitting the dataset into 90% training and 10% validation\n",
    "n_train = int(0.9 * len(val_ds))\n",
    "n_val = len(val_ds) - n_train\n",
    "train_ds, val_ds = torch.utils.data.random_split(val_ds, [n_train, n_val])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds,\n",
    "                                        batch_size=32,\n",
    "                                        shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, \n",
    "                                     batch_size=32, \n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    x, y = val_ds[i]\n",
    "    ax.imshow(x.permute(1, 2, 0))\n",
    "    ax.set_title(f\"Class: {class_names[y].split('/')[-1]}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We use the pre-trained ResNet18 model on ImageNet1k dataset.\n",
    "\n",
    "**NOTE:** Most models come with a pre-processing step which we need to include in our process anytime we use the pre-trained models.\n",
    "\n",
    "[Models and Pre-Trained weights](https://pytorch.org/vision/stable/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18\"\n",
    "resnet_model = torch.hub.load(\"pytorch/vision\", \"resnet18\", weights=ResNet18_Weights.IMAGENET1K_V1, )\n",
    "resnet_model.eval()\n",
    "pre_process = ResNet18_Weights.IMAGENET1K_V1.transforms()\n",
    "print(pre_process)\n",
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning through the FC layer\n",
    "\n",
    "Often, it is enough to only train the Fully-Connected layers. Here we replace the last layer (called `fc` in resnet18) with a randomly initialized linear layer with 365 output classes to match number of classes in our target dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the last layer with a new layer with 365 output classes\n",
    "resnet_model.fc = nn.Linear(512, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation loss before training\n",
    "loss, acc = evaluate(resnet_model, val_dl, nn.CrossEntropyLoss(), device, pre_process)\n",
    "print(f\"Before training | Val loss {loss:.4f} | Val acc {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "freez_not_fc(resnet_model)\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(resnet_model, train_dl, val_dl, criterion, optimizer, device, pre_process, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
